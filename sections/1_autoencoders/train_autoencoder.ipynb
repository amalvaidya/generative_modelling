{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b03b5a-a853-4cda-9919-941275405259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchviz import make_dot\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from autoencoder import AutoEncoder\n",
    "import pickle\n",
    "\n",
    "# https://stackoverflow.com/questions/8223811/a-top-like-utility-for-monitoring-cuda-activity-on-a-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cb3e98-376b-499a-984f-109ae3876e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ebfba-6c9b-4fb0-adcb-ac27a647f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/amal/UbuntuDocuments/data/torch_datasets\"\n",
    "\n",
    "train_data = datasets.CelebA(data_path, split=\"train\", transform=transforms.PILToTensor(), download=True)\n",
    "validation_data =  datasets.CelebA(data_path, split=\"valid\", transform=transforms.PILToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cffca8-bd50-43cf-b017-e51ac6b87fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ad0f9-3951-44bf-a0f7-79608f7a439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    model: torch.nn.Module,\n",
    "    val_dataloader: DataLoader,\n",
    "    device,\n",
    "):\n",
    "    val_loss = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for indx, batch in enumerate(val_dataloader):\n",
    "            input_image = batch[0]\n",
    "            input = torch.tensor(input_image/255, dtype=torch.float).to(device)\n",
    "            output = model(input)\n",
    "\n",
    "            loss = loss_func(output, input)\n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim,\n",
    "    train_loader: DataLoader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "):\n",
    "    # specifcy training mode\n",
    "    model.train()\n",
    "    batch_loss = []\n",
    "    for indx, batch in enumerate(train_loader):\n",
    "    \n",
    "        if indx % 25 == 0:\n",
    "            print(f\"running index: {indx}\")\n",
    "        \n",
    "        input_image = batch[0]\n",
    "        input = torch.tensor(input_image/255, dtype=torch.float).to(device)\n",
    "        output = model(input)\n",
    "    \n",
    "        loss = loss_func(output, input)\n",
    "        batch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return batch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd865edb-dc60-491d-aba3-540d054eb035",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "latent_dim = 200\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(validation_data, batch_size=batch_size)\n",
    "loss_func = nn.MSELoss(reduction = \"mean\")\n",
    "\n",
    "N_epochs = 15\n",
    "out_path = Path(\"/home/amal/UbuntuDocuments/projects/generative_modelling/saved_models\")\n",
    "\n",
    "load_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d411813-70c9-4c97-92b8-b78edb30fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(latent_dim=latent_dim).to(device)\n",
    "opt = optim.Adam(model.parameters())\n",
    "if load_model:\n",
    "    checkpoint_path = out_path / f\"autoencoder_epoch_14.pth\"\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    opt.load_state_dict(checkpoint['optimizer_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae6ff0-62dd-4d91-8632-d1a971ddc1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cfd187-1697-4d5f-a0b4-d8c38c8cfd11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87565087-3f80-4480-b8af-5905aaabaa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(\"losses.pkl\").is_file():\n",
    "    with open(\"losses.pkl\", \"rb\") as f:\n",
    "        losses = pickle.load(f)\n",
    "else:\n",
    "    losses = []\n",
    "\n",
    "\n",
    "batch_loss = []\n",
    "\n",
    "\n",
    "start_epoch = len(losses)\n",
    "\n",
    "TRAIN_MODEL = False\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    for epoch in range(N_epochs):\n",
    "\n",
    "        epoch = start_epoch+epoch\n",
    "        \n",
    "        print(f\"---\\nRunning epoch {epoch + 1}\")\n",
    "        \n",
    "        b_losses = train_epoch(\n",
    "            model,\n",
    "            opt,\n",
    "            train_dataloader,\n",
    "            loss_func,\n",
    "            device\n",
    "        )\n",
    "        epoch_loss = np.mean(b_losses)\n",
    "        val_loss = validate(\n",
    "            model,\n",
    "            val_dataloader,\n",
    "            device,\n",
    "        )\n",
    "    \n",
    "        out = {\n",
    "            \"epoch_loss\" : epoch_loss,\n",
    "            \"val_loss\" : val_loss\n",
    "        }\n",
    "        losses.append(out)\n",
    "        batch_loss = batch_loss + b_losses\n",
    "        out_file = out_path / f\"autoencoder_epoch_{epoch}.pth\"\n",
    "        torch.save(\n",
    "            {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            'train_loss': epoch_loss,\n",
    "            'val_loss' : val_loss    \n",
    "            },\n",
    "            out_file\n",
    "        )\n",
    "\n",
    "    with open(\"losses.pkl\", \"wb\") as f:\n",
    "        pickle.dump(losses, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9676f67b-3f1a-4170-b9f3-d4f6197891ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(batch_loss,)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e67111-8964-4aa8-a1c9-f8117dca1949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3558895-7aa3-4c3f-956d-00b6107fb6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef21c8-b185-4eea-b57f-bed662e3d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f7ee6-eecf-4d4a-a2cd-b7cb19592e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_df.epoch_loss, label = \"train_loss\")\n",
    "plt.plot(loss_df.val_loss, label = \"val loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fab9a47-8a90-4275-86ca-80d0b905e437",
   "metadata": {},
   "source": [
    "## Load checkpoint and evalute model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbfc53a-e3cd-49cf-b64b-6542221a0f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(latent_dim=latent_dim)\n",
    "model.to(device)\n",
    "checkpoint_path = out_path / f\"autoencoder_epoch_14.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7d4bc-3cfe-443c-aae6-f191003e1869",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_index = 5\n",
    "\n",
    "test = torch.tensor(validation_data[val_index][0]/255, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7370a51-f479-44b9-894c-19c327f60b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = model(test.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c673d-7658-4168-a7f8-0ef383cc8817",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c04b6-b0d2-43d0-8852-3c5f35825d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_out.detach().cpu().squeeze().permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba7fd3-c85b-4252-96c9-6b0bf68f2029",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(validation_data[val_index][0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc01503-1d32-4de5-836e-57d532d35d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015812ca-33ba-494d-9ecc-c13722dd7033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75add668-aa02-450c-afaa-c89b696a6eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.recursive_apply(\n",
    "            (218, 178), model.conv_output_shape, 5\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9105b6-426a-48b3-ba48-db8d5952f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "7*6*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cb0031-6bd7-465c-ab3c-9f4e3efa772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "14*12*128, 7*6*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df2452f-ed45-4722-b217-68e115947792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
