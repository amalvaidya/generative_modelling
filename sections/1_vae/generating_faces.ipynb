{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c822f6fa-107a-454c-bb9f-59296759a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from models import AutoEncoder\n",
    "import pickle\n",
    "\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a432a8e-86f8-450e-9e67-4b5b1a11e13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "mpl.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a240ec3b-8e87-4cdd-8999-93a62fae9a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"/home/amal/UbuntuDocuments/projects/generative_modelling/saved_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2dd7e5-4d4c-4e4f-afe7-c9546e3f4e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 200\n",
    "\n",
    "model = AutoEncoder(latent_dim=latent_dim)\n",
    "model.to(device)\n",
    "checkpoint_path = out_path / f\"autoencoder_epoch_9.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e853797-8213-4f6d-a3fe-8a2cb602e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/amal/UbuntuDocuments/data/torch_datasets\"\n",
    "validation_data =  datasets.CelebA(data_path, split=\"valid\", transform=transforms.PILToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d86c6-710e-40f1-964f-c56956f7f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "val_dataloader = DataLoader(validation_data, batch_size=batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88db4c07-711c-4c94-b871-1de64076235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dataset(\n",
    "    model: torch.nn.Module, \n",
    "    dataloader: DataLoader,\n",
    "    device,\n",
    "):\n",
    "\n",
    "    encoded = []\n",
    "    attributes = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for indx, batch in enumerate(dataloader):\n",
    "            input_image = batch[0]\n",
    "            input = torch.tensor(input_image/255, dtype=torch.float).to(device)\n",
    "            _enc = model.encode(input)\n",
    "            encoded.append(_enc.detach().cpu())\n",
    "            attributes.append(batch[1])\n",
    "\n",
    "            if indx > 6:\n",
    "                break\n",
    "\n",
    "    return torch.cat(encoded, dim=0), torch.cat(attributes, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b548b-5525-41dd-906c-8b0fce2f81be",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded, attributes = encode_dataset(model, val_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c35fd0-24be-464c-b086-3079a838ba00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65928b05-7dba-475a-88a1-ac90381a1956",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6633b7e2-2d26-4e7c-aad1-1a05569af94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = torch.mean(encoded, 0)\n",
    "sigmas = torch.std(encoded, dim=0)\n",
    "N_samples = 6\n",
    "torch.mean(encoded), torch.std(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b61a479-a2e3-4be7-8a62-d1a6450b5323",
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = mus.unsqueeze(0).repeat(N_samples, 1)\n",
    "sigmas = sigmas.unsqueeze(0).repeat(N_samples, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f5750-037d-44dd-97a0-fafa0339f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_vectors = torch.normal(mean=mus, std=sigmas).to(device)\n",
    "random_vectors = torch.normal(\n",
    "    mean=torch.zeros(200).repeat(N_samples, 1) + torch.mean(encoded), \n",
    "    std=torch.ones(200).repeat(N_samples, 1) * torch.std(encoded)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a728834-6d19-44a4-bcd2-a94ec377f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vectors[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a7d24e-561c-4c05-9ab6-6f464d22bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "generated_image = model.decode(random_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6be947-b299-40fa-922f-5a59c0098970",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image=generated_image.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e560d3ff-5f35-47e6-a2ef-e41c0701b9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = (generated_image*255).to(torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15398048-aaff-4a70-b0e8-88ab6d1c9c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"/home/amal/UbuntuDocuments/writing/blog/generative_ml/images/vae\")\n",
    "SAVE = True\n",
    "for i in range(N_samples):\n",
    "    plt.imshow(generated_image[i, :].squeeze().permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    if SAVE:\n",
    "        plt.savefig(output_dir / f\"ae_random_gen_{i}.png\", bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6305a92-23a6-4a9f-b7c7-1981e2b4637c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
