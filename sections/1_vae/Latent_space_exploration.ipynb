{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac3267ff-0e93-4d4a-b7c0-fab399b6b0fd",
   "metadata": {},
   "source": [
    "# Now lets explore the latent space a litte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5180b084-0bf7-410c-8265-cd8e07576602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from models import AutoEncoder, VAE\n",
    "import pickle\n",
    "\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d51649-5b68-40a9-a85c-50b973cf7b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=5WoItGTWV54&ab_channel=StanfordUniversitySchoolofEngineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccabf58-586d-4322-9bf0-9615e5d6dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "mpl.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e2df71-9f38-4b7b-bf6a-67c11f10bb1d",
   "metadata": {},
   "source": [
    "## Start by loading the model and the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b330c87b-bd76-424f-8ae3-c0f465ac5a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"/home/amal/UbuntuDocuments/projects/generative_modelling/saved_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5694b2-bff3-4b1c-9760-a0206bea9a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 200\n",
    "\n",
    "model = VAE(latent_dim=latent_dim)\n",
    "model.to(device)\n",
    "checkpoint_path = out_path / f\"VAE_epoch_14.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c57544b-9550-4399-bab5-e9a781bb8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_labels = [\n",
    "    '5_o_Clock_Shadow',\n",
    "    'Arched_Eyebrows',\n",
    "    'Attractive',\n",
    "    'Bags_Under_Eyes',\n",
    "    'Bald',\n",
    "    'Bangs',\n",
    "    'Big_Lips',\n",
    "    'Big_Nose',\n",
    "    'Black_Hair',\n",
    "    'Blond_Hair',\n",
    "    'Blurry',\n",
    "    'Brown_Hair',\n",
    "    'Bushy_Eyebrows',\n",
    "    'Chubby',\n",
    "    'Double_Chin',\n",
    "    'Eyeglasses',\n",
    "    'Goatee',\n",
    "    'Gray_Hair',\n",
    "    'Heavy_Makeup',\n",
    "    'High_Cheekbones',\n",
    "    'Male',\n",
    "    'Mouth_Slightly_Open',\n",
    "    'Mustache',\n",
    "    'Narrow_Eyes',\n",
    "    'No_Beard',\n",
    "    'Oval_Face',\n",
    "    'Pale_Skin',\n",
    "    'Pointy_Nose',\n",
    "    'Receding_Hairline',\n",
    "    'Rosy_Cheeks',\n",
    "    'Sideburns',\n",
    "    'Smiling',\n",
    "    'Straight_Hair',\n",
    "    'Wavy_Hair',\n",
    "    'Wearing_Earrings',\n",
    "    'Wearing_Hat',\n",
    "    'Wearing_Lipstick',\n",
    "    'Wearing_Necklace',\n",
    "    'Wearing_Necktie'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01da2a2-7bb4-4312-9bb7-be17135bebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/amal/UbuntuDocuments/data/torch_datasets\"\n",
    "validation_data =  datasets.CelebA(data_path, split=\"valid\", transform=transforms.PILToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0f657f-fa94-4042-a677-eb2e1ae88ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "val_dataloader = DataLoader(validation_data, batch_size=batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2991767f-9ce6-4686-8935-074a64f4c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dataset(\n",
    "    model: torch.nn.Module, \n",
    "    dataloader: DataLoader,\n",
    "    device,\n",
    "):\n",
    "\n",
    "    encoded = []\n",
    "    attributes = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for indx, batch in enumerate(dataloader):\n",
    "            input_image = batch[0]\n",
    "            input = torch.tensor(input_image/255, dtype=torch.float).to(device)\n",
    "            _enc, _, _ = model.encode(input)\n",
    "            encoded.append(_enc.detach().cpu())\n",
    "            attributes.append(batch[1])\n",
    "\n",
    "            if indx > 6:\n",
    "                break\n",
    "\n",
    "    return torch.cat(encoded, dim=0), torch.cat(attributes, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c0c551-ab4c-4be4-a593-5cc61da9f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded, attributes = encode_dataset(model, val_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a0de4-98e1-4f3f-8517-d82fc187674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e71dad8-10ae-4a17-8bcc-9cd7ec822f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(10, 8))\n",
    "fig.tight_layout()\n",
    "axes = axes.flatten()\n",
    "\n",
    "indices = np.random.choice(np.arange(latent_dim), len(axes), replace=False)\n",
    "\n",
    "for i, feature in enumerate(indices):\n",
    "\n",
    "    axes[i].hist(encoded[:, feature], bins=50)\n",
    "    axes[i].set_title(f\"dim {feature}, ($\\mu = ${torch.mean(encoded[:, feature]):.2f}, $\\sigma = ${torch.std(encoded[:, feature]):.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a743c1-7fc1-4006-8160-279b0b8217e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a093e7-b8c3-4afd-9b45-945fe00e267f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c2468-faec-48f4-a8d2-d644dfef8af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = encoded.cpu().detach().numpy()\n",
    "attributes = attributes.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef19a162-044f-46b6-90c8-7812b2bfb8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_reduction = umap.UMAP(n_components=2, n_neighbors=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d950f9-cc8d-4c7e-90ec-591a36c21eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = dim_reduction.fit_transform(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4260e79-3a9c-4085-aa07-720e4253135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.scatterplot(x=reduced[:, 0], y=reduced[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aacfe0-a1dd-4e58-9acb-47b785b3da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7e79a0-55a2-4de7-a7eb-b724ff114b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[*(enumerate(attribute_labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cbe5fd-366d-4720-b78c-68d89d7de016",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = 'Wearing_Hat'\n",
    "\n",
    "sel_index = attribute_labels.index(attr)\n",
    "labels =  attributes[:, sel_index] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eea720b-444a-4ccb-93ac-05c1decae047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.scatterplot(x=reduced[:, 0], y=reduced[:, 1], hue=labels)\n",
    "# plt.legend(title='Smoker', loc='upper left', labels=[attr, 'Nah Bruh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a33150-98ec-42e3-a632-906fc465901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 7))\n",
    "\n",
    "size = 30\n",
    "e_color = 'black'\n",
    "linewidth=0.6\n",
    "alpha=0.7\n",
    "\n",
    "plt.scatter(x=reduced[attributes[:, sel_index] != 1, 0], y=reduced[attributes[:, sel_index] != 1, 1], s=size, edgecolors=e_color, linewidth = linewidth, alpha=alpha)\n",
    "plt.scatter(x=reduced[attributes[:, sel_index] == 1, 0], y=reduced[attributes[:, sel_index] == 1, 1], s=size, edgecolors=e_color, linewidth =linewidth, alpha=alpha, label=attr.replace(\"_\", \" \"))\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3f134e-987a-407a-8093-06875bda2aad",
   "metadata": {},
   "source": [
    "## Try and visualise the data in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6db75-e197-47e5-bd95-1e0dcdf45a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_reduction_3d = umap.UMAP(n_components=3, n_neighbors=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b525562-a97e-44bd-8aaf-928b047dc522",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_3d = dim_reduction_3d.fit_transform(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048c493-699c-466c-b82d-bb9307f7adad",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf8612f-877b-44b5-918e-45336b15c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.5\n",
    "linewidth=0.6\n",
    "e_color = 'black'\n",
    "size = 10\n",
    "\n",
    "plt.scatter(\n",
    "    x=reduced_3d[:, 0], \n",
    "    y=reduced_3d[:, 1],\n",
    "     s=size, edgecolors=e_color, linewidth = linewidth, alpha=alpha\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e56e3-2c70-4e9c-9538-f0936f64d00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(reduced_3d[:, 1], reduced_3d[:, 2], reduced_3d[:, 0],  s=size, edgecolors=e_color, linewidth = linewidth, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e8a92-5104-47ac-b32d-efed6aa33d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
